{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# pytorch and numpy"
      ],
      "metadata": {
        "id": "nMMGqtfTO3ob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy and PyTorch are two fundamental libraries in the Python ecosystem, widely used in scientific computing, data analysis, and machine learning, particularly deep learning. While they share some conceptual similarities, their primary focuses and capabilities differ.\n",
        "\n",
        "* Data in NumPy , want in python tensor ->\n",
        "`torch.from_numpy(ndarray)`\n",
        "\n",
        "* PyTorch tensor , want in NumPy -> `torch.Tensor.numpy()`"
      ],
      "metadata": {
        "id": "71NExFUUPDhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QWdbBSVMOOG0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array = np.arange(1.0 , 11.0)\n",
        "numpy_array , numpy_array.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNBIkJNCPpd7",
        "outputId": "484e2d0b-2955-4d9e-9afa-ace95303c62b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), dtype('float64'))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_from_nparray = torch.from_numpy(numpy_array)\n",
        "tensor_from_nparray , tensor_from_nparray.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DNUQyaFPzVB",
        "outputId": "ec939674-5335-43cb-f153-fb5e28c6e34a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=torch.float64),\n",
              " torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we change something in array it will not reflect in pytorch\n",
        "numpy_array = numpy_array + 1\n",
        "numpy_array , tensor_from_nparray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBT2ljQtRuQb",
        "outputId": "ef7e3f8f-988e-4589-c720-9e8cee43dedf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),\n",
              " tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When creating a NumPy array without explicitly specifying the dtype, NumPy attempts to infer the most appropriate data type based on the input values. **(default dtype)**\n",
        "\n",
        "For **integers**:\n",
        "the default data type is typically int64 on most modern 64-bit systems, or int32 on 32-bit systems. This corresponds to the size of a C long on the specific platform.\n",
        "\n",
        "For **floating-point numbers**:\n",
        "If the array contains floating-point numbers, the default data type is typically float64, which represents double-precision floating-point numbers."
      ],
      "metadata": {
        "id": "MRPBpY3IQgXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_array = torch.arange(1.0 , 11.0)\n",
        "pytorch_array , pytorch_array.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKhDqdaoQqt9",
        "outputId": "1d6a0654-f065-4205-e3a9-a2c5dc3c58da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nparray_from_pytorch = pytorch_array.numpy()\n",
        "nparray_from_pytorch , nparray_from_pytorch.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd0O2UL-Q4gs",
        "outputId": "c66665f2-aae6-4510-e2ef-86b3570c55cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=float32),\n",
              " dtype('float32'))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default floating-point data type for PyTorch tensors (often referred to as PyTorch arrays) is torch.float32. This corresponds to a 32-bit single-precision floating-point number."
      ],
      "metadata": {
        "id": "dtTQOpbyRFj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Warning` : when converting from numpy -> pytorch , pytorch reflects numpy's default dtype unless specified and vice versa"
      ],
      "metadata": {
        "id": "mpUjog2nRPba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you change something in pytorch array it will not reflect in numpy array\n",
        "pytorch_array = pytorch_array +1\n",
        "pytorch_array , nparray_from_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nry8CqbZRHN3",
        "outputId": "82541b98-5452-401c-f907-4e0fd9769d0d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),\n",
              " array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reproducability (trying to take random out of random):\n",
        "\n",
        "how a neural network learns:\n",
        "* start with random numbers\n",
        "* perform tensor operations\n",
        "* update random numbers to try and make them better representations of the data\n",
        "* again and again"
      ],
      "metadata": {
        "id": "3CuSWo8TSfmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any time you create a random tensor , with `torch.rand` , its going to give different numbers every time you run it\n",
        "\n",
        "To reduce the randomness in neural networks and pytorch , comes the concept of a **random seed**\n",
        "\n",
        "Setting a random seed in PyTorch is crucial for achieving reproducibility in experiments and debugging. It ensures that operations *relying* on random number generation produce the same results across different runs."
      ],
      "metadata": {
        "id": "r07UduoZS9Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(3,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5jYHd4pS4Vm",
        "outputId": "001376e5-1ce1-4c7c-8ae3-93ba23f13ed8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5314, 0.1197, 0.2840],\n",
              "        [0.3097, 0.8956, 0.8843],\n",
              "        [0.3615, 0.6731, 0.3152]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor_A = torch.rand(3,4)\n",
        "random_tensor_B = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "# its highly unlikely that these tensors have some same values\n",
        "print(random_tensor_A == random_tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GiF1xhoT4h6",
        "outputId": "6be4cfdb-f56e-473d-83ae-7ebda070ed19"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1830, 0.2901, 0.4245, 0.3045],\n",
            "        [0.5474, 0.4404, 0.7304, 0.8722],\n",
            "        [0.0985, 0.4736, 0.5450, 0.1385]])\n",
            "tensor([[0.7728, 0.6115, 0.3991, 0.9294],\n",
            "        [0.9587, 0.9401, 0.4073, 0.4925],\n",
            "        [0.5309, 0.3167, 0.0560, 0.8165]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you share this piece of code with someone else theyre going to get another numbers too and its highly unlikely for them to get same values too"
      ],
      "metadata": {
        "id": "mxDRalToUNyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will remain same everytime you run it\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfWORZ02UIxP",
        "outputId": "ec99ae0c-91e4-4b4a-8f83-7167447b3a0c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.manual_seed(random_seed)` generally only works for one block of code below it\n",
        "\n",
        "* This is a way of flavoring the randomness"
      ],
      "metadata": {
        "id": "qkscC9x-VZFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will remain same everytime you run it\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3,4)\n",
        "\n",
        "RANDOM_SEED2 = 46\n",
        "torch.manual_seed(RANDOM_SEED2)\n",
        "random_tensor_D = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knjNRlORV389",
        "outputId": "59d5c8a1-8868-401a-f5f9-33e8cd847f30"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.6611, 0.0600, 0.5174, 0.1596],\n",
            "        [0.7550, 0.8390, 0.0674, 0.4631],\n",
            "        [0.1477, 0.3597, 0.9328, 0.0170]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Tensors and PyTorch objects on the GPUs\n",
        "\n",
        "GPUs = faster computation on numbers , because of CUDA + NVIDIA hardware + PyTorch working behind to scenes to make everything good."
      ],
      "metadata": {
        "id": "_kVFQ9A7WyW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a GPU:\n",
        "\n",
        "1. Use google colab - easiest method\n",
        "2. Use your own GPU\n",
        "3. Use cloud computing - GCP , AWS , Azure\n",
        "(these services allow you to rent computers on the clous and access them)\n",
        "\n",
        "2,3 require setting up , use PyTorch's documentation for that"
      ],
      "metadata": {
        "id": "JISJe9puXJ6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYB9SFJFXGgt",
        "outputId": "dd78f541-fe6f-4d30-b0bd-7c5456339bb2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul 18 16:34:56 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch requires almost no setup for this\n",
        "\n",
        "Check for GPU access with pytorch - `torch.cuda.is_available()`"
      ],
      "metadata": {
        "id": "cJPwacKYZOi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoPYW4opY4dl",
        "outputId": "0a9c060f-3e62-4c8e-c1c0-5f40d66698bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might not always have a GPU but if its available you can use it"
      ],
      "metadata": {
        "id": "2NtSmF5SugUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Device-agnostic code**: Device-agnostic code in PyTorch refers to writing code that can seamlessly run on different hardware devices, primarily CPUs and GPUs, without requiring significant modifications."
      ],
      "metadata": {
        "id": "7SOOEWOluq4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For PyTorch , since its capable of running compute on the GPU or CPU , its best practice to setup device agnostic code\n",
        "\n",
        "eg: run on GPU if available else default cpu\n",
        "\n",
        "you can set it using python code too"
      ],
      "metadata": {
        "id": "BWMRVtL6voum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "npZKBI0mZju-",
        "outputId": "2dbfd693-2eff-492b-a7ad-5395f60a7a6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are running huge models on large datasets , you might want to run one model on certain GPU , another model on another GPU and so on"
      ],
      "metadata": {
        "id": "PW7e9mHavOJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count number of devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdpMMLspvFIp",
        "outputId": "c029f12f-a3f9-4006-b94b-203a7ad7416e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting tensors (and models) on the GPU\n",
        "\n",
        "The reason we want our tensors/models on the GPU is beacuse using a GPU results in faster computations\n",
        "\n"
      ],
      "metadata": {
        "id": "tQ18Wz5QwNiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor (default on cpu)\n",
        "tensor = torch.tensor([1,2,3] , device = \"cpu\")\n",
        "print(tensor , tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAiG4LWzwNSi",
        "outputId": "a0955270-43b1-4322-a186-139273d3b2b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xecWjDBPw_k3",
        "outputId": "54d72363-b955-4877-ee2a-c0bbce2267c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving tensors back to CPU"
      ],
      "metadata": {
        "id": "thlWWYvYxn96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another big error in PyTorch is device error , we can not transform a Tensor to NumPy if its on GPU"
      ],
      "metadata": {
        "id": "6d35f9Q-xZA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device error:\n",
        "tensor_on_gpu.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "GbgLiTUqxmd9",
        "outputId": "f7acabb1-0ac1-4246-8c29-eda230893c5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-4150330584.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# device error:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix the GPU tensor with NumPy issue , we can first set it to the CPU - using `tensor.cpu()` and then convert it to NumPy using `.numpy()`"
      ],
      "metadata": {
        "id": "OHDFMHb5x1ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_back_to_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_to_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKp9H3jGxy2t",
        "outputId": "41258c83-f96f-4866-d27b-f16a992bc6cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch fundamentals exercises"
      ],
      "metadata": {
        "id": "IO-8jDpJzH0k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VYNr-Jf1xyzS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
